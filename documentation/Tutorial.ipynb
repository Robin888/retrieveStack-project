{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "\n",
    "Use handwritting digit recognization data for exhibit how to use retriveStacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from scikit-learn dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "random.seed( 3 )\n",
    "\n",
    "\n",
    "digits =load_digits()\n",
    "data=pd.DataFrame(digits.data).reset_index()\n",
    "data['target']=digits.target\n",
    "predictors=list(data)\n",
    "predictors.remove('target')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************************************\n",
    "Split dataset to train and test (train for training model and test to validate model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data[predictors], data['target'], test_size=0.333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************************************\n",
    "Load packages; choose several models with default settings; assign models to each layer (3 layer in total,layer 3 is output layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from retrieveStack.retrieveEnsemble import ensemble\n",
    "from retrieveStack.retrieveEnsemble import opt_weight,retrieve\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier,RandomForestRegressor,ExtraTreesRegressor,GradientBoostingClassifier,GradientBoostingRegressor\n",
    "\n",
    "knc=KNeighborsClassifier()\n",
    "dtc=DecisionTreeClassifier(random_state=4321)\n",
    "rfc=RandomForestClassifier(random_state=4321)\n",
    "etc=ExtraTreesClassifier(random_state=4321)\n",
    "\n",
    "knr=KNeighborsRegressor()\n",
    "dtr=DecisionTreeRegressor(random_state=4321)\n",
    "rfr=RandomForestRegressor(random_state=4321)\n",
    "etr=ExtraTreesRegressor(random_state=4321)\n",
    "\n",
    "\n",
    "layer1=[knc,dtc,rfc,etc,knr,dtr,rfr,etr]\n",
    "layer2=[knc,dtc,rfc,etc,knr,dtr,rfr,etr]\n",
    "layer3=[knc,dtc,rfc,etc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**********************************************************************************************************************************************\n",
    "\n",
    "train first layer, generate input data for next layer and record model information in this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer1 model 0 is 1.86236783862\n",
      "*******************************************************\n",
      "1 DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=4321, splitter='best')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer1 model 1 is 5.49982675429\n",
      "*******************************************************\n",
      "2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "            verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer1 model 2 is 0.571192293199\n",
      "*******************************************************\n",
      "3 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer1 model 3 is 0.369354847991\n",
      "*******************************************************\n",
      "4 KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer1 model 4 is 4.1613775062\n",
      "*******************************************************\n",
      "5 DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=4321,\n",
      "           splitter='best')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer1 model 5 is 3.34339540366\n",
      "*******************************************************\n",
      "6 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer1 model 6 is 1.63579320761\n",
      "*******************************************************\n",
      "7 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "          verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer1 model 7 is 1.34504988523\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "trainX_l1,testX_l1,modelInfo_l1=ensemble(layer_name='layer1',models=layer1,\n",
    "                                         train_x=train_X,train_y=train_Y,test_x=test_X,\n",
    "                                         n_classes=10,n_folds=10,\n",
    "                                         metric_for_classifier='log_loss',\n",
    "                                         metric_for_regressor='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************************************\n",
    "train second layer, generate input data for next layer and record model information in this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer2 model 0 is 1.37412274099\n",
      "*******************************************************\n",
      "1 DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=4321, splitter='best')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer2 model 1 is 2.46335561796\n",
      "*******************************************************\n",
      "2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "            verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer2 model 2 is 0.381722611883\n",
      "*******************************************************\n",
      "3 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer2 model 3 is 0.425243080813\n",
      "*******************************************************\n",
      "4 KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "          weights='uniform')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer2 model 4 is 0.895664186602\n",
      "*******************************************************\n",
      "5 DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=4321,\n",
      "           splitter='best')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer2 model 5 is 1.37180760282\n",
      "*******************************************************\n",
      "6 RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer2 model 6 is 0.727679570311\n",
      "*******************************************************\n",
      "7 ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "          min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "          n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "          verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the mean_squared_error of layer2 model 7 is 0.703749091897\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "trainX_l2,testX_l2,modelInfo_l2=ensemble(layer_name='layer2',models=layer2,\n",
    "                                         train_x=trainX_l1,train_y=train_Y,test_x=testX_l1,\n",
    "                                         n_classes=10,n_folds=10,\n",
    "                                         metric_for_classifier='log_loss',\n",
    "                                         metric_for_regressor='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************************************\n",
    "train third layer, generate input data for next layer and record model information in this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer3 model 0 is 1.45967013013\n",
      "*******************************************************\n",
      "1 DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=4321, splitter='best')\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer3 model 1 is 2.14079537509\n",
      "*******************************************************\n",
      "2 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "            verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer3 model 2 is 0.516558779862\n",
      "*******************************************************\n",
      "3 ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=4321,\n",
      "           verbose=0, warm_start=False)\n",
      "Fold 0 - Fold 1 - Fold 2 - Fold 3 - Fold 4 - Fold 5 - Fold 6 - Fold 7 - Fold 8 - Fold 9 - All folds Done!\n",
      "the log_loss of layer3 model 3 is 0.526010806985\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "trainX_l3,testX_l3,modelInfo_l3=ensemble(layer_name='layer3',models=layer3,\n",
    "                                         train_x=trainX_l2,train_y=train_Y,test_x=testX_l2,\n",
    "                                         n_classes=10,n_folds=10,\n",
    "                                         metric_for_classifier='log_loss',\n",
    "                                         metric_for_regressor='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************************************\n",
    "Find the good models by comparing score with the output layer (third layer), and combine with output layer's models to weighted average prediction. opt_weight function can give out the cv score after weight averaging and the optimized weight for all the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score after weighted averaging is 0.139577532013\n"
     ]
    }
   ],
   "source": [
    "good=retrieve([modelInfo_l1,modelInfo_l2,modelInfo_l3],metric='log_loss',maximize=False)\n",
    "\n",
    "bestScore,optWeight=opt_weight(modelInfo_list=good,train_y=train_Y,metric='log_loss',method='SLSQP',maximize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************************************************************************************************************************\n",
    "Output the prediction using optimized weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849749582637729"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from retrieveStack.retrieveEnsemble import predict_proba,predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred=predict(good,optWeight,majority_voting=True)\n",
    "accuracy_score(test_Y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the accuracy with single models in first layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94490818030050083"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,etc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95492487479131882"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,rfc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85642737896494159"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,dtc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76627712854757934"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,knc.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27378964941569284"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knr.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,[int(round(e)) for e in knr.predict(test_X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80300500834724542"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,[int(round(e)) for e in dtr.predict(test_X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60601001669449084"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,[int(round(e)) for e in rfr.predict(test_X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62103505843071782"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etr.fit(train_X,train_Y)\n",
    "accuracy_score(test_Y,[int(round(e)) for e in etr.predict(test_X)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a look at the result of conventional feedforward stacking (without retrieving back to find good models, only use model from output layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score after weighted averaging is 0.392044925247\n"
     ]
    }
   ],
   "source": [
    "bestScore2,optWeight2=opt_weight(modelInfo_list=modelInfo_l3,train_y=train_Y,metric='log_loss',method='SLSQP',maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98163606010016691"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=predict(modelInfo_l3,optWeight2,majority_voting=True)\n",
    "accuracy_score(test_Y,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "From above it can see, the retrived stacking can improve the accuracy of prediction greatly without tuning any parameter. The accuracy of retrieveStack is 98.5%, while the best single model only gives a 95.3% accuarcy. Furthermore, compared to conventional feedforward stacking without retrieving (accuracy 98.2%), the retrieving process do improve the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
